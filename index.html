<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Analysis of Single-Factor Experiments (ANOVA)</title>
    <meta charset="utf-8" />
    <meta name="author" content="Adi Sarid" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/rutgers-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Analysis of Single-Factor Experiments (ANOVA)
## Lecture #10
### Adi Sarid
### Tel-Aviv University
### updated: 2020-01-04

---


&lt;style type="text/css"&gt;

.remark-code {
  font-size: 24px;
}

.huge { 
  font-size: 200%;
}
.tiny .remark-code {
  font-size: 50%;
}

.small .remark-code{
   font-size: 85% !important;
}

.small {
   font-size: 85% !important;
}

.remark-slide-content {
    font-size: 20px;
    padding: 1em 4em 1em 4em;
}

table { display: inline-block; }

th, td {
   padding: 5px;
}

.small-slide {
   font-size: 70% !important;
}

.image-50 img {
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 50%;
}

.right-plot {
   width: 60%;
   float: right;
   padding-left: 1%;
   bottom: 0px;
   right: 0px;
   position: absolute;
}



&lt;/style&gt;



# Reminder from Previous Lecture (Multiple Regression Exercise)

.small[
The `ChickWeight` dataset contains the results of a feeding experiment of 50 chicks' (`Chick`) with their tracked weight (`weight`), over a period of 21 days (`Time`), each chick was subjected to a different type of diet (`Diet`).

In the following model (see bottom of slide), we are using the interaction of `Time*factor(Diet)` as one of the explanatory variables, along with `Time` as another explanatory variable. The dependent variable is the chick's `weight`.

Questions:

   1. The original `Diet` variable is numeric. Why are we using it in the regression model as `factor(Diet)`?

   1. How many levels does the `factor(Diet)` variable has, explain.
   
   2. Why do we need the interaction of `Time*factor(Diet)` in the model? (why is `weight ~ Time + factor(Diet)` not enough)
   
   3. Which dietary method helps increase the chick's weight the most? Explain how you deduced this from the model's output.

See the next slide for an additional question.
]

.tiny[

```r
chick_lm &lt;- lm(formula = weight ~ Time + Time*factor(Diet), data = ChickWeight)
summary(chick_lm)
```

```
## 
## Call:
## lm(formula = weight ~ Time + Time * factor(Diet), data = ChickWeight)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -135.425  -13.757   -1.311   11.069  130.391 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         30.9310     4.2468   7.283 1.09e-12 ***
## Time                 6.8418     0.3408  20.076  &lt; 2e-16 ***
## factor(Diet)2       -2.2974     7.2672  -0.316  0.75202    
## factor(Diet)3      -12.6807     7.2672  -1.745  0.08154 .  
## factor(Diet)4       -0.1389     7.2865  -0.019  0.98480    
## Time:factor(Diet)2   1.7673     0.5717   3.092  0.00209 ** 
## Time:factor(Diet)3   4.5811     0.5717   8.014 6.33e-15 ***
## Time:factor(Diet)4   2.8726     0.5781   4.969 8.92e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 34.07 on 570 degrees of freedom
## Multiple R-squared:  0.773,	Adjusted R-squared:  0.7702 
## F-statistic: 277.3 on 7 and 570 DF,  p-value: &lt; 2.2e-16
```
]

---

# Test-like Exercises: Interpretation of a Model's Output - continued

Look at the following qqplot of residuals and plot of the residuals as a function of time. 

   4. Explain what are the underlying assumptions of the linear regression model.
   
   5. Observing the residuals' plots below, would you say that any of the linear regressions assumptions are violated? which one?

&lt;img src="08-Single_factor_experiments_ANOVA_files/figure-html/qqplot and residuals-1.png" style="display: block; margin: auto;" /&gt;

---

# Experiment Design - Motivation

With methods of hypothesis testing, we were able to discern the differences between two groups (i.e., unpaird two-sample test).

For example trying to see if cars with 4 cylinders are more efficient than cars with 8 cylinders.

.small[

```r
mtcars %&gt;% 
   filter(cyl != 6) %&gt;% 
   t.test(formula = mpg ~ cyl, data = .)
```

```
## 
## 	Welch Two Sample t-test
## 
## data:  mpg by cyl
## t = 7.5967, df = 14.967, p-value = 1.641e-06
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##   8.318518 14.808755
## sample estimates:
## mean in group 4 mean in group 8 
##        26.66364        15.10000
```
]

---

# Experiment Design - Motivation (2)

Sometimes, we have more than two levels, in which case, we would like to devise a test which will compare all levels.

--

In the case of a single variable with multiple levels, this is called *single factor experiments* (in the next lecture we will also discuss *multi factor experiments*, when there are multiple levels).

--

The process invloves:

   * Conjecture - The hypothesis that motivates the experiment
   
   * Experiment - The actual test performed to investigate the conjecture
   
   * Analysis - Statistical analysis of the collected data
   
   * Conclusions - What has been learned
   
The process is iterated: to improve the experiment (e.g., add new variables or change the methods) and learn more.

--

.small[The following material is covered in Montgomery chapter 13.]

---

# Experiment Design - Motivation (3)

We would like a statistical that would highlight the efficiency of cars as a function of the number of cylinders. 

--

A boxplot can visually illustrate what we are looking for, but we cannot yield strength or significance from it.


```r
ggplot(mtcars, aes(y = mpg, x = factor(cyl))) + 
   geom_boxplot(fill = "lightblue") + 
   theme_bw()
```

&lt;img src="08-Single_factor_experiments_ANOVA_files/figure-html/mtcars cyl comparison-1.png" style="display: block; margin: auto;" /&gt;

--

Question: How would you use linear regression to examine this relationship?

---

# The Completely Randomized Single-Factor Experiment

Each factor level is called a *treatment* (i.e., for different treatments administered in an experiment).

--

The experimenter randomely samples subjects (either of equally sized groups or varying sized groups).

--

We describe the observations for a **completely randomized design** by a linear statistical model:

`$$Y_{ij} = \mu + \tau_i + \epsilon_{ij}, \quad i = 1,\ldots,\ j=1,\ldots n$$`

The value `\(\mu_i=\mu+\tau_i\)` is the mean value of the `\(i\)`th treatment.

--

We assume that the errors `\(\epsilon_{i,j}\)` are normally and independently distributed `\(\mathcal{N}(0, \sigma^2)\)`.

--

Two methods to select the treatments:

   * **Fixed-effects model**: the `\(a\)` treatments were chosen specifically.
   
   * **Random-effects model** (components of variance): the `\(a\)` treatments were a random sample from a larger population of treatments. We would like to extend the conclusions for additional treatments.

--

For now, we are going to focus on the **fixed effects model**.

---

# The Fixed-Effects Model

The treatments `\(\tau_i\)` are defined as deviations from the overall mean `\(\mu\)` such that: 

`$$\sum_{i=1}^a{\tau_i}=0$$`

--

Define:

`$$y_{i\cdot}=\sum_{j=1}^n{y_{ij}}, \quad \bar{y}_{i\cdot}=y_{i\cdot}/n$$`

`$$y_{\cdot\cdot} = \sum_{i=1}^a\sum_{j=1}^n{y_{ij}}, \quad \bar{y}_{\cdot\cdot}=y_{\cdot\cdot}/N, \quad N=a\cdot n$$`

--

We are interested in the following test:

   * `\(H_0: \tau_1=\ldots=\tau_a=0\)`
   
   * `\(H_1: \exists i\ |\ \tau_i\neq0\)`

---

# The Sum of Squares

Again, we use the sum of squares equation: `\(SS_T = SS_\text{Treatments} + SS_E\)`:

`$$\sum_{i=1}^a\sum_{j=1}^n({y_{ij} - \bar{y}_{\cdot\cdot})^2} = n\sum_{i=1}^a{(\bar{y}_{i\cdot} - \bar{y}_{\cdot\cdot})^2} + \sum_{i=1}^a\sum_{j=1}^n({y_{ij} - \bar{y}_{i\cdot})^2}$$`

--

The expected value of each of the errors is given by:

`$$E(SS_\text{Treatments})=(a-1)\sigma^2 + n\sum_{i=1}^a{\tau_i^2}$$`

`$$E(SS_E) = a(n-1)\sigma^2$$`

--

The degrees of freedom of each error are: 

   * `\(an-1\)` for `\(SS_T\)`, 
   * `\(a-1\)` for `\(SS_\text{Treatments}\)` 
   * `\(a(n-1)\)` for `\(SS_E\)`
   
---

# The ANOVA Test

If the null hypothesis holds, then `\(\tau_1=\ldots=\tau_a=0\)`, and

--

`\(MS_\text{Treatments}=SS_\text{Treatments}/(a-1)\)` is an unbiased estimator of `\(\sigma^2\)`

--

The error mean square `\(MS_E=SS_E/[a(n-1)]\)` is also an unbiased estimator of `\(\sigma^2\)`

--

Hence the following statistic has an F-distribution

`$$F_0=\frac{SS_\text{Treatments}/(a-1)}{SS_E/[a(n-1)]}=\frac{MS_\text{Treatments}}{MS_E}$$`

With `\(a-1\)` and `\(a(n-1)\)` degrees of freedom.

--

We use an upper-tail, one-sided critical region and reject `\(H_0\)` if `\(f_0&gt;f_{\alpha, a-1, a(n-1)}\)`.

---

# The ANOVA Table

The corresponding ANOVA table, for a Single-Factor Experiment, with a Fixed-Effects Model:

| Source of Variation | Sum of Squares | df | Mean Squares | `\(F_0\)` |
|----------------------|-----------------|-------|:------------:|---------------------|
| Treatments | `\(SS_\text{Treatments}\)` | `\(a-1\)` | `\(MS_\text{Treatments}\)` | `\(\frac{MS_\text{Treatments}}{MS_E}\)` |
| Error | `\(SS_E\)` | `\(a(n-1)\)` | `\(MS_E\)` |  |
| Total | `\(SS_T\)` | `\(an-1\)` |  |  |

--

For an unbalanced experiment (each treatment has varying group size, `\(n_i\)`) we would have:

`$$SS_T=\sum_{i=1}^a\sum_{j=1}^{n_i}{y_{ij}^2} - \frac{y_{\cdot\cdot}^2}{N}$$`

`$$SS_\text{Treatments} = \sum_{i=1}^a\frac{y_{i\cdot}^2}{n_i} - \frac{y_{\cdot\cdot}^2}{N}$$`

And `\(SS_E = SS_T-SS_\text{Treatment}\)`

---

# ANOVA Example


```r
mtcars2 &lt;- mtcars %&gt;% 
   mutate(cyl_fct = factor(cyl))
mtcars_anova &lt;- aov(formula = mpg ~ cyl_fct, data = mtcars2)
summary(mtcars_anova)
```

```
##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## cyl_fct      2  824.8   412.4    39.7 4.98e-09 ***
## Residuals   29  301.3    10.4                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

--

Usually, ANOVA will be followed by a multiple comparisons procedures, that will help identify which factors contribute to the variation.

--

There are many such multiple comparison tests. See [this book](http://www.ievbras.ru/ecostat/Kiril/R/Biblio_N/R_Eng/Bretz2011.pdf): Bretz F., Hothorn T., and Westfall P., Multiple Comparisons Using R, CRC Press, 2011.

---

# Dunnett's  Test

The one-sided Dunnett's test takes the minimum (or maximum depending on direction) of the `\(a\)` pairwise `\(t\)` tests:

`$$t_i=\frac{\bar{y}_{i\cdot}-\bar{y}_0}{s\sqrt{\frac{1}{n_i} + \frac{1}{n_0}}}$$`

Where `\(y_0\)` relates to the control group (to which we are comparing the treatments), and `\(s^2\)` is the pooled variance, i.e.:

`$$s^2=\sum_{i=0}^m\sum_{j=1}^{n_j}(y_{ij}-\bar{y}_{i\cdot})^2/v$$`

With `\(v = \sum_{i=0}^m{n_i}-(a+1)\)` degrees of freedom.

--

The Dunnett's test is availble in `multcomp` like many other procedures for multiple comparisons.

---

# Dunnett's Test Example
.small[

```r
suppressWarnings(suppressMessages(library(multcomp)))
glht(mtcars_anova,
     linfct = mcp(cyl_fct = "Dunnett"),
     alternative = "less") %&gt;% 
   summary()
```

```
## 
## 	 Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Dunnett Contrasts
## 
## 
## Fit: aov(formula = mpg ~ cyl_fct, data = mtcars2)
## 
## Linear Hypotheses:
##            Estimate Std. Error t value   Pr(&lt;t)    
## 6 - 4 &gt;= 0   -6.921      1.558  -4.441 0.000117 ***
## 8 - 4 &gt;= 0  -11.564      1.299  -8.905 8.54e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## (Adjusted p values reported -- single-step method)
```
]

---

# Verifying ANOVA assumptions
.small[
The ANOVA model assumes that observations are normally and independently distributed, with the same variance for each treatment. 

This can be verified using hypothesis tests on the residuals, or viewing a proper plot (e.g., qqplot). The following illustrates that some assumptions are invalid in the previous example (which?) 
]
.tiny[

```r
mtcars2_resid &lt;- mtcars2 %&gt;% 
   mutate(resid = mtcars_anova$residuals)
boxplot_resid &lt;- ggplot(mtcars2_resid, aes(x = cyl_fct, y = resid)) + 
   geom_boxplot(fill = "lightblue") +
   theme_bw() + ggtitle("Boxplot of residuals in each cyl level")
qqplot_resid &lt;- ggplot(mtcars2_resid, aes(sample = (resid - mean(resid))/sd(resid))) + 
   geom_qq() + 
   theme_bw() + ggtitle("QQ plot of residuals")
cowplot::plot_grid(qqplot_resid, boxplot_resid)
```

&lt;img src="08-Single_factor_experiments_ANOVA_files/figure-html/verifying normality-1.png" style="display: block; margin: auto;" /&gt;
]

---

# Determining the Sample Size

The selection of the sample size is based on the difference we want to detect, and at what test power:

`$$1-\beta = P(\text{Reject } H_0 | H_1) = P(F_0&gt;f_{1-\alpha, a-1, a(n-1)} | H_1)$$`

--

The effect size represents the differences in means between groups:

`$$\operatorname{ES} = \frac{\mu_\text{experiment}-\mu_\text{control}}{s}$$`
.small[

```r
pwr::pwr.anova.test(k = 3, n = NULL, f = 0.25, sig.level = 0.05, power = 0.8)
```

```
## 
##      Balanced one-way analysis of variance power calculation 
## 
##               k = 3
##               n = 52.3966
##               f = 0.25
##       sig.level = 0.05
##           power = 0.8
## 
## NOTE: n is number in each group
```
]

---

# The Random-Effects Model (Factor with Many Levels)

In cases the factor has a large number of levels, we cannot sample all of them. We would like to sample part of them, `\(a\)` levels, and draw conclusions about the entire population of factor levels.

--

As before, we define

`$$Y_{ij} = \mu + \tau_i + \epsilon_{ij}$$`

However, this time, the factor has a variance, i.e.:

`$$\operatorname{Var}(Y_{ij}) = \sigma_\tau^2 + \sigma^2$$`

--

We would like to test the hypothesis that:

   * `\(H_0:\sigma_\tau^2=0\)`
   
   * `\(H_1:\sigma_\tau^2&gt;0\)`
   
If `\(H_0\)` holds, this means that the treatments are identical. 

--

If `\(\sigma_\tau^2&gt;0\)` this means that there is variability between treatments.

---

# The Random-Effects Model - Continued

The relationship of residuals still holds:

`$$SS_T = SS_\text{Treatments} + SS_E$$`

But the errors change:

`$$E(MS_\text{Treatments}) = E\left[\frac{SS_\text{Treatments}}{a-1}\right] = \sigma^2 + n\sigma^2_\tau$$`

`$$E(MS_E) = E\left[\frac{SS_E}{a(n-1)}\right] = \sigma^2$$`

--

Under the null hypothesis both sizes are identical and hence

`$$F_0=\frac{MS_\text{Treatments}}{MS_E}$$`

Is an F-distributed variable with `\(a-1\)` and `\(a(n-1)\)` degrees of freedom.

---

# Determining the Sample Size in the Random Effects Model

We would like to find `\(n\)` for a given `\(\beta\)` (type-II error) such that:

`$$1-\beta = P(\text{Reject } H_0|H_1)=P(F_0&gt;f_{\alpha, a-1, a(n-1)}|\sigma_\tau&gt;0)$$`

--

If `\(H_1\)` is true, then the ratio `\(\frac{MS_\text{Treatments}/(\sigma^2+n\sigma_\tau^2)}{MS_E/\sigma^2}\)` has the `\(F\)`-distribution with `\(a-1\)` and `\(a(n-1)\)` degrees of freedom. Then,

`$$1-\beta = P\left(\frac{MS_\text{Treatements}}{MS_E}&gt;f_{\alpha, a-1, a(n-1)}|\sigma^2_\tau&gt;0\right) = 
P\left(\frac{MS_\text{Treatements}}{MS_E/(1+n\sigma^2_\tau/\sigma^2)}&gt;\frac{f_{\alpha, a-1, a(n-1)}}{(1+n\sigma^2_\tau/\sigma^2)}\right)$$`

--

Hence,

`$$1-\beta = P\left(F_{a-1, a(n-1)}&gt;\frac{f_{\alpha, a-1, a(n-1)}}{(1+n\sigma^2_\tau/\sigma^2)}\right)$$`

If we assume something about `\(\sigma_\tau^2/\sigma^2\)`, we can calculate the desired `\(n\)`, using the `\(F\)` distribution function.

---

# Random-Effects Model - Example

When manufacturing food and drugs (medication) we usually aim for having a high degree of consistency, so that different batches produce the same product (quality, concentration, etc.). 

Consistency is not trivial to produce: production lines malfunction, shifts change, and machinery is sometimes replaced. 

The random effects model can be used to determine if consistency of the production lines should be rejected.

--

## The model - Olive oil acidity 

   * We are manufacturing olive oil, and each batch should have an acidity level of 0.5%
   
   * The factory wants to design an experiment which will test if the acidity is consistent.
   
   * Questions: What is our factor? What are the factor levels?
   
---

# Example - Olive oil acidity

The batch is our factor. It has many levels and therefore we treat it is a random effect.

--

`$$\text{acidity} = \mu + \tau_\text{batch} + \epsilon_{batch,j}$$`
.tiny[

```r
oil_manufacturing &lt;- tibble(
   batch = factor(c("A", "A", "A", "A", "B", "B", "B", "B", "B", 
                    "C", "C", "C", "C", "D", "D", "E", "E")),
   acidity = 
      c(0.45, 0.49, 0.51, 0.50, 0.49, 0.60, 0.55, 0.41, 0.36, 
        0.50, 0.51, 0.49, 0.48, 0.50, 0.51, 0.08, 0.20))

oil_aov &lt;- aov(formula = acidity ~ batch, data = oil_manufacturing)
summary(oil_aov)
```

```
##             Df  Sum Sq Mean Sq F value   Pr(&gt;F)    
## batch        4 0.21707 0.05427   13.43 0.000219 ***
## Residuals   12 0.04851 0.00404                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

```r
TukeyHSD(oil_aov)
```

```
##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = acidity ~ batch, data = oil_manufacturing)
## 
## $batch
##        diff        lwr        upr     p adj
## B-A -0.0055 -0.1414408  0.1304408 0.9999276
## C-A  0.0075 -0.1357942  0.1507942 0.9997988
## D-A  0.0175 -0.1579988  0.1929988 0.9974654
## E-A -0.3475 -0.5229988 -0.1720012 0.0003058
## C-B  0.0130 -0.1229408  0.1489408 0.9978453
## D-B  0.0230 -0.1465480  0.1925480 0.9917589
## E-B -0.3420 -0.5115480 -0.1724520 0.0002574
## D-C  0.0100 -0.1654988  0.1854988 0.9997182
## E-C -0.3550 -0.5304988 -0.1795012 0.0002507
## E-D -0.3650 -0.5676486 -0.1623514 0.0007205
```
]

---

# Example - Olive Oil Acidity (cont.)

We can use Dunnett's test to specify the exact contrasts we would like to examine:

.small[

```r
library(multcomp)
glht(oil_aov,
     linfct = mcp(batch = c("E-A=0", "E-B=0", "E-C=0", "E-D=0"))) %&gt;% 
   summary()
```

```
## 
## 	 Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: User-defined Contrasts
## 
## 
## Fit: aov(formula = acidity ~ batch, data = oil_manufacturing)
## 
## Linear Hypotheses:
##            Estimate Std. Error t value Pr(&gt;|t|)    
## E - A == 0 -0.34750    0.05506  -6.311 0.000102 ***
## E - B == 0 -0.34200    0.05319  -6.429  &lt; 1e-04 ***
## E - C == 0 -0.35500    0.05506  -6.448  &lt; 1e-04 ***
## E - D == 0 -0.36500    0.06358  -5.741 0.000237 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## (Adjusted p values reported -- single-step method)
```
]

---

# Randomized Complete Block Design

Sometimes we have an additional factor which is not the aim of the study. For example, imagine a clinical research where `\(a\)` treatments are used in `\(b\)` medical centers.

--

It might be that the fact that there are varying medical centers in itself influences the results.

--

If the selection of treatments is ranodmized across medical centers, the experiment is called a randomized complete block design.

--

|  | Blocks |  |  |  |  |  |
|------------|--------------------|--------------------|---------:|---------------------|------------------|-------------------|
| Treatments | 1 | 2 | `\(\ldots\)` | `\(b\)` | Totals | Averages |
| 1 | `\(y_{11}\)` | `\(y_{12}\)` | `\(\ldots\)` | `\(y_{1b}\)` | `\(y_{1\cdot}\)` | `\(\bar{y}_{1\cdot}\)` |
| `\(\vdots\)` |  |  | `\(\vdots\)` |  |  | `\(\vdots\)` |
| `\(a\)` | `\(y_{a1}\)` | `\(y_{a2}\)` | `\(\ldots\)` | `\(y_{ab}\)` | `\(y_{a\cdot}\)` | `\(\bar{y}_{a\cdot}\)` |
| Totals | `\(y_{\cdot1}\)` | `\(y_{\cdot2}\)` | `\(\ldots\)` | `\(y_{\cdot b}\)` | `\(y_{\cdot\cdot}\)` |  |
| Averages | `\(\bar{y}_{\cdot1}\)` | `\(\bar{y}_{\cdot2}\)` | `\(\ldots\)` | `\(\bar{y}_{\cdot b}\)` |  |  |

---

# Randomized Complete Block Design (cont.)

The formula for this design is given by:

`$$Y_{ij}=\mu + \tau_i + \beta_j + \epsilon_{ij}, \quad i\in\{1,\ldots,a\},j\in\{1,\ldots,b\}$$`

Where

   * `\(\mu\)` is the overall mean.
   
   * `\(\tau_i\)` is the effect of the `\(i\)`th treatment.
   
   * `\(\beta_j\)` is the effect of the `\(j\)`th block.
   
   * `\(\epsilon_{ij}\)` is the error term `\(\epsilon_{ij}\sim\mathcal{N}(0,\sigma)\)`
   
--

We assume that the treatments and blocks are fixed factors, and that they are deviations from the overall mean, so `\(\sum_{i=1}^a{\tau_i}=0\)` and `\(\sum_{j=1}^b{\beta_j}=0\)`. We test the hypothesis:

   * `\(H_0: \tau_1=\ldots=\tau_a=0\)`
   * `\(H_1: \exists i: \tau_i\neq0\)`

---

# Sum of Squares Identity in the Randomized Complete Block Design

The sum of squares identity can be broken into

`$$\sum_{i=1}^a\sum_{j=1}^b(y_{ij}-\bar{y}_{\cdot\cdot})^2 = b\sum_{i=1}^a{(\bar{y}_{i\cdot}-\bar{y}_{\cdot\cdot})^2} + a\sum_{j=1}^b{(\bar{y}_{\cdot j}-\bar{y}_{\cdot\cdot})^2}+\sum_{i,j}{(y_{ij}-\bar{y}_{\cdot j} - \bar{y}_{i\cdot} + \bar{y}_{\cdot\cdot})^2}$$`
--

Symbolically stated as

`$$SS_T = SS_\text{Treatments} + SS_\text{Blocks} + SS_E$$`

--

With degrees of freedom:

`$$ab-1 = (a-1) + (b-1) + (a-1)(b-1)$$`

---

# Randomized Complete Block Design Hypothesis Test

Set:

`$$MS_\text{Treatments} = \frac{SS_\text{Treatments}}{a-1},\quad MS_\text{Blocks} = \frac{SS_\text{Blocks}}{b-1},\quad MS_E=\frac{SS_E}{(a-1)(b-1)}$$`

--

The mean sum of squares is given by:

   * `\(E(MS_\text{Treatments}) = \sigma^2 + \frac{b\sum_{i=1}^a{\tau_i^2}}{a-1}\)`
   
   * `\(E(MS_\text{Blocks}) = \sigma^2 + \frac{a\sum_{j=1}^b{\beta_j^2}}{b-1}\)`
   
   * `\(E(MS_E) = \sigma^2\)`
   
--

If `\(H_0\)` is true and all `\(\tau_i=0\)` then:

`$$F_0=\frac{MS_\text{Treatments}}{MS_E}$$`

Is `\(F\)`-distributed with `\(a-1\)` and `\((a-1)(b-1)\)` degrees of freedom.

---

# Example for Randomized Complete Block Design - ANOVA

An experiment was performed to determine the effect of four chemicals on the fabric strength (Example 13.5 from Montgomery).

.tiny[

```r
fabric_strength &lt;- read_csv("https://raw.githubusercontent.com/adisarid/intro_statistics_R/master/lectures/data/montgomery_13.5_fabric_strength.csv", col_types = cols()) %&gt;% 
   pivot_longer(cols = -chemical, names_to = "fabric_sample", values_to = "strength") %&gt;% 
   mutate(chemical = factor(chemical))

fabric_aov &lt;- aov(formula = strength ~ chemical + fabric_sample, data = fabric_strength)
summary(fabric_aov)
```

```
##               Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## chemical       3 18.044   6.015   75.89 4.52e-08 ***
## fabric_sample  4  6.693   1.673   21.11 2.32e-05 ***
## Residuals     12  0.951   0.079                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

```r
TukeyHSD(fabric_aov)
```

```
##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = strength ~ chemical + fabric_sample, data = fabric_strength)
## 
## $chemical
##      diff         lwr       upr     p adj
## 2-1  0.62  0.09140218 1.1485978 0.0204200
## 3-1  0.24 -0.28859782 0.7685978 0.5523215
## 4-1  2.42  1.89140218 2.9485978 0.0000001
## 3-2 -0.38 -0.90859782 0.1485978 0.1973362
## 4-2  1.80  1.27140218 2.3285978 0.0000017
## 4-3  2.18  1.65140218 2.7085978 0.0000002
## 
## $fabric_sample
##                   diff        lwr          upr     p adj
## fabric2-fabric1  0.225 -0.4094912  0.859491196 0.7881457
## fabric3-fabric1 -1.425 -2.0594912 -0.790508804 0.0000922
## fabric4-fabric1 -0.100 -0.7344912  0.534491196 0.9855599
## fabric5-fabric1 -0.400 -1.0344912  0.234491196 0.3180795
## fabric3-fabric2 -1.650 -2.2844912 -1.015508804 0.0000212
## fabric4-fabric2 -0.325 -0.9594912  0.309491196 0.5059326
## fabric5-fabric2 -0.625 -1.2594912  0.009491196 0.0542123
## fabric4-fabric3  1.325  0.6905088  1.959491196 0.0001857
## fabric5-fabric3  1.025  0.3905088  1.659491196 0.0018293
## fabric5-fabric4 -0.300 -0.9344912  0.334491196 0.5771595
```
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
